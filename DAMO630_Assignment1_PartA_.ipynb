{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4160b8",
   "metadata": {},
   "source": [
    "\n",
    "# DAMO630 – Assignment 1 (Final Patched)\n",
    "\n",
    "**Generated:** 2025-10-04 02:01  \n",
    "\n",
    "- Fixes `yes`/`no` (and similar) targets in **TSTR** by mapping to 0/1.\n",
    "- Ensures correlation-preservation metric is always a scalar.\n",
    "- Adds a consolidated **Results Table** + CSV export.\n",
    "- `%pip install` cells enabled for Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83baa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install dependencies (run once per session)\n",
    "%pip install --quiet pandas numpy scipy scikit-learn matplotlib Faker\n",
    "%pip install --quiet sdv ctgan copulas\n",
    "%pip install --quiet pyspark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd86308",
   "metadata": {},
   "source": [
    "## Part A — Privacy-Preserving Analytics with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6594e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "URL = \"https://vincentarelbundock.github.io/Rdatasets/csv/AER/HealthInsurance.csv\"\n",
    "df = pd.read_csv(URL)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print(\"Shape:\", df.shape); print(\"Numeric:\", numeric_cols); print(\"Categorical:\", categorical_cols)\n",
    "display(df.describe(include='all').transpose())\n",
    "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick EDA plots\n",
    "for col in numeric_cols:\n",
    "    plt.figure(); df[col].plot(kind='hist', bins=30, edgecolor='k', alpha=0.8)\n",
    "    plt.title(f\"Histogram: {col}\"); plt.xlabel(col); plt.ylabel(\"Count\"); plt.show()\n",
    "for col in categorical_cols:\n",
    "    plt.figure(); df[col].value_counts().head(20).plot(kind='bar', edgecolor='k', alpha=0.8)\n",
    "    plt.title(f\"Bar chart: {col} (Top 20)\"); plt.xlabel(col); plt.ylabel(\"Count\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation matrix (numeric only)\n",
    "if len(numeric_cols) > 1:\n",
    "    corr = df[numeric_cols].corr(numeric_only=True)\n",
    "    display(corr)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.imshow(corr, cmap='coolwarm', interpolation='nearest')\n",
    "    plt.title(\"Correlation matrix (numeric)\"); plt.colorbar()\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print(\"Not enough numeric columns for correlation matrix.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be756ee1",
   "metadata": {},
   "source": [
    "### Baseline Synthetic (sampling + noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3aba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(42)\n",
    "\n",
    "def baseline_synth(df_real, noise_scale=0.05, n_samples=None):\n",
    "    if n_samples is None:\n",
    "        n_samples = len(df_real)\n",
    "    data = {}\n",
    "    for col in df_real.columns:\n",
    "        s = df_real[col].dropna()\n",
    "        if s.empty:\n",
    "            data[col] = [None]*n_samples\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            vals = s.to_numpy()\n",
    "            choices = rng.choice(vals, size=n_samples, replace=True)\n",
    "            std = np.std(vals) if np.std(vals) > 0 else 1e-8\n",
    "            noise = rng.normal(0, std*noise_scale, size=n_samples)\n",
    "            data[col] = choices + noise\n",
    "        else:\n",
    "            vals = s.to_numpy()\n",
    "            data[col] = rng.choice(vals, size=n_samples, replace=True)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "synth_base = baseline_synth(df)\n",
    "print(\"Baseline synthetic shape:\", synth_base.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e367e0bd",
   "metadata": {},
   "source": [
    "### SDV Models: CTGAN & GaussianCopula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae322462",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sdv.single_table import CTGANSynthesizer, GaussianCopulaSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(df)\n",
    "\n",
    "ctgan = CTGANSynthesizer(metadata, epochs=200)\n",
    "ctgan.fit(df)\n",
    "synth_ctgan = ctgan.sample(num_rows=len(df))\n",
    "\n",
    "gauss = GaussianCopulaSynthesizer(metadata)\n",
    "gauss.fit(df)\n",
    "synth_gauss = gauss.sample(num_rows=len(df))\n",
    "\n",
    "print(\"CTGAN:\", synth_ctgan.shape, \"GaussianCopula:\", synth_gauss.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60738b8b",
   "metadata": {},
   "source": [
    "### Evaluation Helpers (KS, Correlation, TSTR, Privacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9003be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import numpy as _np\n",
    "\n",
    "def ks_similarity(real, synth, numeric_cols):\n",
    "    rows = []\n",
    "    for col in numeric_cols:\n",
    "        r = real[col].dropna(); s = synth[col].dropna()\n",
    "        if len(r) > 5 and len(s) > 5:\n",
    "            stat, p = ks_2samp(r, s)\n",
    "            rows.append({\"feature\": col, \"KS_stat\": float(stat), \"pvalue\": float(p)})\n",
    "    return pd.DataFrame(rows).sort_values(\"feature\")\n",
    "\n",
    "def corr_preservation(real, synth, numeric_cols):\n",
    "    if len(numeric_cols) < 2:\n",
    "        return pd.DataFrame({\"mean_abs_corr_diff\":[None]})\n",
    "    rc = real[numeric_cols].corr(numeric_only=True).to_numpy()\n",
    "    sc = synth[numeric_cols].corr(numeric_only=True).to_numpy()\n",
    "    mask = _np.triu(_np.ones_like(rc, dtype=bool), k=1)\n",
    "    mae = float(_np.abs(rc[mask] - sc[mask]).mean())\n",
    "    return pd.DataFrame({\"mean_abs_corr_diff\":[mae]})\n",
    "\n",
    "def tstr_utility(real, synth):\n",
    "    # Pick an existing binary target if present\n",
    "    target = None\n",
    "    for col in real.columns:\n",
    "        vals = real[col].dropna().unique()\n",
    "        if len(vals) == 2:\n",
    "            target = col; break\n",
    "\n",
    "    tmp_real = real.copy(); tmp_synth = synth.copy()\n",
    "\n",
    "    # If none, create an auto target from a numeric median split (or random if no numerics)\n",
    "    if target is None:\n",
    "        numc = real.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        target = \"__auto_binary_target\"\n",
    "        if numc:\n",
    "            thr = real[numc[0]].median()\n",
    "            tmp_real[target] = (real[numc[0]] > thr).astype(int)\n",
    "            tmp_synth[target] = (synth[numc[0]] > thr).astype(int)\n",
    "        else:\n",
    "            tmp_real[target] = (_np.random.rand(len(real)) > 0.5).astype(int)\n",
    "            tmp_synth[target] = (_np.random.rand(len(synth)) > 0.5).astype(int)\n",
    "\n",
    "    # Map yes/no/true/false/\"1\"/\"0\" to integers if needed\n",
    "    for df_tmp in [tmp_real, tmp_synth]:\n",
    "        if df_tmp[target].dtype == object:\n",
    "            df_tmp[target] = df_tmp[target].astype(str).str.lower().map(\n",
    "                {\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0}\n",
    "            ).fillna(0).astype(int)\n",
    "\n",
    "    Xs = tmp_synth.drop(columns=[target], errors='ignore'); ys = tmp_synth[target].astype(int)\n",
    "    Xr = tmp_real.drop(columns=[target], errors='ignore'); yr = tmp_real[target].astype(int)\n",
    "\n",
    "    num_cols = Xr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = [c for c in Xr.columns if c not in num_cols]\n",
    "\n",
    "    pre = ColumnTransformer([(\"num\", \"passthrough\", num_cols),\n",
    "                             (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)])\n",
    "\n",
    "    clf = Pipeline([(\"pre\", pre), (\"lr\", LogisticRegression(max_iter=1000))])\n",
    "    clf.fit(Xs, ys)\n",
    "    proba = clf.predict_proba(Xr)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return {\"ACC\": float(accuracy_score(yr, preds)), \"ROC_AUC\": float(roc_auc_score(yr, proba))}\n",
    "\n",
    "def privacy_row_duplication(real, synth):\n",
    "    real_tuples = set(map(tuple, real.dropna(axis=1, how=\"all\").itertuples(index=False, name=None)))\n",
    "    synth_tuples = set(map(tuple, synth.dropna(axis=1, how=\"all\").itertuples(index=False, name=None)))\n",
    "    return {\"exact_row_overlaps\": int(len(real_tuples & synth_tuples))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1455eaa6",
   "metadata": {},
   "source": [
    "### Per-model Metrics Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe09bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, s in [(\"Baseline\", synth_base), (\"CTGAN\", synth_ctgan), (\"GaussianCopula\", synth_gauss)]:\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    ks = ks_similarity(df, s, numeric_cols); display(ks.head(10))\n",
    "    corrp = corr_preservation(df, s, numeric_cols)\n",
    "    try:\n",
    "        corr_val = float(corrp[\"mean_abs_corr_diff\"].iloc[0])\n",
    "    except Exception:\n",
    "        corr_val = None\n",
    "    print(\"Correlation preservation (mean abs corr diff):\", corr_val)\n",
    "    t = tstr_utility(df, s); print(\"TSTR:\", t)\n",
    "    priv = privacy_row_duplication(df, s); print(\"Privacy:\", priv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6224258",
   "metadata": {},
   "source": [
    "### Consolidated Results Table + CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for name, s in [(\"Baseline\", synth_base), (\"CTGAN\", synth_ctgan), (\"GaussianCopula\", synth_gauss)]:\n",
    "    ksdf = ks_similarity(df, s, numeric_cols)\n",
    "    ks_mean = float(ksdf[\"KS_stat\"].mean()) if not ksdf.empty else None\n",
    "    ks_median = float(ksdf[\"KS_stat\"].median()) if not ksdf.empty else None\n",
    "\n",
    "    corrp = corr_preservation(df, s, numeric_cols)\n",
    "    try:\n",
    "        corr_mae = float(corrp[\"mean_abs_corr_diff\"].iloc[0])\n",
    "    except Exception:\n",
    "        corr_mae = None\n",
    "\n",
    "    tstr = tstr_utility(df, s)\n",
    "    acc = tstr.get(\"ACC\"); auc = tstr.get(\"ROC_AUC\")\n",
    "    overlap = privacy_row_duplication(df, s).get(\"exact_row_overlaps\")\n",
    "\n",
    "    rows.append({\"Model\": name, \"KS_mean\": ks_mean, \"KS_median\": ks_median,\n",
    "                 \"Corr_MAE\": corr_mae, \"TSTR_ACC\": acc, \"TSTR_ROC_AUC\": auc,\n",
    "                 \"Exact_Row_Overlaps\": overlap})\n",
    "\n",
    "results_df = pd.DataFrame(rows).set_index(\"Model\")\n",
    "display(results_df)\n",
    "results_path = \"Assignment1_results.csv\"\n",
    "results_df.to_csv(results_path, index=True)\n",
    "print(\"Saved:\", results_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084760a",
   "metadata": {},
   "source": [
    "## Part B — NYC Taxi Trip Data with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0579dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"NYC-Taxi-Analysis\").getOrCreate()\n",
    "# Add your Spark I/O and analytics here (FPGrowth, KMeans, etc.) as needed.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}